{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqeCciFESCfk",
        "outputId": "653e7488-a66a-4eb3-f5ec-a5d4ff7237af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRJOfW3XKof_"
      },
      "source": [
        "# Market Basket Analysis with Spark (FP-Growth)\n",
        "**Project 2:** Market-Basket Analysis\n",
        "\n",
        "**Author:** Precious Prince\n",
        "\n",
        "**Course:** Algorithms for Massive Data, Master's in Data Science for Economics, University of Milan\n",
        "\n",
        "**Goal:** Recommend books to users based on co-occurrence patterns and rank those recommendations using average user ratings.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-EmWYKyLvg-"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0nP2bSKvL3O2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.ml.fpm import FPGrowth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQNWMSCuL7OS"
      },
      "source": [
        "### Kaggle API Setup and Dataset Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AylyBVEoL-7u",
        "outputId": "acb9d588-9b67-429b-d36d-697f25220747"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews\n",
            "License(s): CC0-1.0\n",
            "Downloading amazon-books-reviews.zip to /content\n",
            " 93% 0.99G/1.06G [00:06<00:01, 39.6MB/s]\n",
            "100% 1.06G/1.06G [00:06<00:00, 169MB/s] \n",
            "Archive:  amazon-books-reviews.zip\n",
            "  inflating: amazon_books_reviews/Books_rating.csv  \n",
            "  inflating: amazon_books_reviews/books_data.csv  \n"
          ]
        }
      ],
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"preciousprince33\"\n",
        "os.environ['KAGGLE_KEY'] = \"47e70b1e0bf52f6f0f3b6a3ac4bf04f9\"\n",
        "!kaggle datasets download -d mohamedbakhet/amazon-books-reviews\n",
        "!unzip amazon-books-reviews.zip -d amazon_books_reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMZ_vt3NMAyy"
      },
      "source": [
        "### Initialize Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IVQ8eXXZMDx9"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.appName(\"MarketBasketAnalysis\").getOrCreate()\n",
        "\n",
        "# Load dataset files\n",
        "ratings_df = spark.read.csv(\"amazon_books_reviews/Books_rating.csv\", header=True, inferSchema=True, quote='\"', escape='\"', multiLine=True)\n",
        "book_df = spark.read.csv(\"amazon_books_reviews/books_data.csv\", header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zIaNC6ZMHwl"
      },
      "source": [
        "### Data Cleaning and Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qh3g0NtxMMDV"
      },
      "outputs": [],
      "source": [
        "# Sampling for quicker local testing; the global variable can control this.\n",
        "\n",
        "sample_df = ratings_df.sample(withReplacement=False, fraction=0.01, seed=42)\n",
        "sample_df = sample_df.dropna(subset=['User_id', 'Id', 'Title'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6KPg29QMVHQ"
      },
      "source": [
        "### Basket Creation (User â†’ List of Books Reviewed (Amazon Standard Identification Number (ASIN)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "B5rvEoyaMaJP"
      },
      "outputs": [],
      "source": [
        "# Each user represents a basket, and the items are books they reviewed.\n",
        "# Filter only users who reviewed at least 2 books.\n",
        "baskets_id_df = sample_df.groupBy(\"User_id\").agg(F.collect_list(\"Id\").alias(\"basket\"))\n",
        "baskets_id_df = baskets_id_df.withColumn(\"basket\", F.array_distinct(F.col(\"basket\")))\n",
        "baskets_id_df = baskets_id_df.filter(F.size(F.col(\"basket\")) >= 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAc-Pq9IM3B5"
      },
      "source": [
        "### FP-Growth Model for Frequent Itemset Mining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKHVIw2EM4cl"
      },
      "outputs": [],
      "source": [
        "MIN_SUPPORT = 0.001  # Minimum fraction of baskets containing the itemset(Support measures how frequently an item or itemset appears in the dataset.)\n",
        "MIN_CONFIDENCE = 0.5  # Minimum confidence for association rules (Confidence measures how strongly one item implies another.)\n",
        "\n",
        "fp_growth = FPGrowth(itemsCol=\"basket\", minSupport=MIN_SUPPORT, minConfidence=MIN_CONFIDENCE)\n",
        "model = fp_growth.fit(baskets_id_df)\n",
        "association_rules = model.associationRules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I used minSupport = 0.001 to focus on books co-reviewed by at least 0.1% of users, ensuring that only meaningful and frequent co-occurrences were included.\n",
        "\n",
        "minConfidence = 0.5 was chosen to retain only strong associations, where the consequent appeared in at least half of the baskets containing the antecedent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvAzq4dtWBBd",
        "outputId": "9be5cf8b-17b6-44e5-b878-fb4cee5a36c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Total number of association rules: 15\n"
          ]
        }
      ],
      "source": [
        "# Count total number of association rules generated by FP-Growth\n",
        "num_rules = association_rules.count()\n",
        "print(f\"Total number of association rules: {num_rules}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unique_antecedents = association_rules.select(\"antecedent\").distinct().count()\n",
        "print(f\"Unique antecedent itemsets: {unique_antecedents:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYt3Ql-XNCGP"
      },
      "source": [
        "### Add Titles to Association Rules for Readability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vI_AAYkZNGQF"
      },
      "outputs": [],
      "source": [
        "# Many books share similar titles but have different ASINs (paperback, hardcover, different sellers, etc.).\n",
        "# If only the title is exactly the same, then only it would be rejected.\n",
        "# To avoid recommending the same title again, we'll use both ASIN and title checks.\n",
        "\n",
        "# Map ASIN (Id) to Title\n",
        "title_mapping = sample_df.select(\"Id\", \"Title\").dropna().distinct()\n",
        "\n",
        "# Join titles to association rules for better readability\n",
        "rules_readable = (\n",
        "    association_rules\n",
        "    # extract ASINs from the item arrays\n",
        "    .withColumn(\"antecedent_asin\", F.element_at(F.col(\"antecedent\"), 1))\n",
        "    .withColumn(\"consequent_asin\", F.element_at(F.col(\"consequent\"), 1))\n",
        "    # join titles\n",
        "    .join(\n",
        "        title_mapping.withColumnRenamed(\"Id\", \"a_Id\").withColumnRenamed(\"Title\", \"antecedent_title\"),\n",
        "        F.col(\"antecedent_asin\") == F.col(\"a_Id\"),\n",
        "        \"left\"\n",
        "    )\n",
        "    .join(\n",
        "        title_mapping.withColumnRenamed(\"Id\", \"c_Id\").withColumnRenamed(\"Title\", \"consequent_title\"),\n",
        "        F.col(\"consequent_asin\") == F.col(\"c_Id\"),\n",
        "        \"left\"\n",
        "    )\n",
        "    # remove duplicates where antecedent and consequent refer to same title\n",
        "    .filter(F.lower(F.col(\"antecedent_title\")) != F.lower(F.col(\"consequent_title\")))\n",
        "    # keep relevant columns\n",
        "    .select(\n",
        "        \"antecedent_asin\",\n",
        "        \"antecedent_title\",\n",
        "        \"consequent_asin\",\n",
        "        \"consequent_title\",\n",
        "        \"confidence\",\n",
        "        \"support\"\n",
        "    )\n",
        ")\n",
        "\n",
        "print(\" Readable association rules created:\", rules_readable.count())\n",
        "rules_readable.show(10, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since many books share the same title but differ in ASIN (e.g., paperback vs hardcover), I merged the FP-Growth results with the title mapping and filtered identical-title pairs to avoid redundant recommendations.\n",
        "This cleaning step ensured that recommendations represent genuinely distinct books rather than format duplicates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fQ4b7mvN10B"
      },
      "source": [
        "### Compute Average Rating per Book"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Lwj1klYOLHe"
      },
      "outputs": [],
      "source": [
        "# We'll use this to rank recommendations by quality.\n",
        "# Compute average rating for each book (from sampled data)\n",
        "avg_rating_df = (\n",
        "    sample_df\n",
        "    .groupBy(\"Id\")\n",
        "    .agg(F.avg(\"review/score\").alias(\"avg_rating\"))\n",
        ")\n",
        "\n",
        "# Join average rating on the consequent (recommended) books\n",
        "rules_with_rating = (\n",
        "    rules_readable\n",
        "    .join(\n",
        "        avg_rating_df.withColumnRenamed(\"Id\", \"c_Id\"),\n",
        "        F.col(\"consequent_asin\") == F.col(\"c_Id\"),\n",
        "        \"left\"\n",
        "    )\n",
        "    .drop(\"c_Id\")\n",
        ")\n",
        "\n",
        "print(\"âœ… Rules enriched with average ratings.\")\n",
        "rules_with_rating.select(\"antecedent_title\", \"consequent_title\", \"confidence\", \"avg_rating\").show(10, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To prioritize higher-quality recommendations, each consequent book was enriched with its average user rating. This allows sorting recommendations by a combined relevance-and-quality score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zumm8JPCWST3",
        "outputId": "9fc5b74e-7476-4d1b-b82b-f33fc8ab35f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Total number of rules after same titles and ASINs: 12\n"
          ]
        }
      ],
      "source": [
        "print(f\"Total number of rules after same titles and ASINs: {rules_with_rating.count()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OImaCWqTORmX"
      },
      "source": [
        "### Generate Personalized Recommendations per User"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kP6uuaPBOd23"
      },
      "outputs": [],
      "source": [
        "user_suggestions = (\n",
        "    baskets_id_df.alias(\"u\")\n",
        "    # Join rules whose antecedent is present in the user's basket\n",
        "    .join(\n",
        "        rules_with_rating.alias(\"r\"),\n",
        "        F.array_contains(F.col(\"u.basket\"), F.col(\"r.antecedent_asin\")),\n",
        "        \"inner\"\n",
        "    )\n",
        "    .select(\n",
        "        F.col(\"u.User_id\").alias(\"user_id\"),\n",
        "        F.col(\"r.antecedent_asin\"),\n",
        "        F.col(\"r.antecedent_title\"),\n",
        "        F.col(\"r.consequent_asin\"),\n",
        "        F.col(\"r.consequent_title\"),\n",
        "        F.col(\"r.confidence\"),\n",
        "        F.col(\"r.support\"),\n",
        "        F.col(\"r.avg_rating\"),\n",
        "        F.col(\"u.basket\")\n",
        "    )\n",
        ")\n",
        "\n",
        "print(\"âœ… User-level suggestions created:\", user_suggestions.count())\n",
        "user_suggestions.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For each user basket, the FP-Growth rules whose antecedent books appear in the basket were joined to generate personalized recommendations. The resulting table lists, for each user, the recommended book titles, their confidence, and average rating scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j1Owuv9Ovgf"
      },
      "source": [
        "### Filter Out Already Read or Duplicate Books"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4b1eZeiP_6a"
      },
      "outputs": [],
      "source": [
        "#  Remove books the user already reviewed\n",
        "user_suggestions_filtered = user_suggestions.filter(\n",
        "    ~F.array_contains(F.col(\"basket\"), F.col(\"consequent_asin\"))\n",
        ")\n",
        "\n",
        "#  Remove duplicates: same user & same title (different ASIN)\n",
        "user_suggestions_unique = (\n",
        "    user_suggestions_filtered\n",
        "    .dropDuplicates([\"user_id\", \"consequent_title\"])\n",
        ")\n",
        "\n",
        "print(\"Cleaned user recommendations:\", user_suggestions_unique.count())\n",
        "user_suggestions_unique.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After generating preliminary recommendations, two filtering steps were applied:\n",
        "- Books already present in the userâ€™s basket were excluded to avoid redundancy;\n",
        "- Duplicates with identical titles but different ASINs were removed.\n",
        "\n",
        "This ensured that final recommendations were novel and unique for each user."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_Y8HEYGP9UN"
      },
      "source": [
        "### Sort Recommendations by Average Rating (Descending)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd1fbHT4QM7r",
        "outputId": "9f69564b-ae33-44a5-97d9-03a4ffc3e708"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------+-----------------------------------------------------------------------------------------------------------------------------------+\n",
            "|user_id       |recommended_books_sorted                                                                                                           |\n",
            "+--------------+-----------------------------------------------------------------------------------------------------------------------------------+\n",
            "|A1D2C0WDCSHUWZ|[{1, 1581730470, Emma, 4.428571428571429, 0.5, 0.0014903129657228018}]                                                             |\n",
            "|A1NT7ED5TATUAM|[{1, 0520050894, A Connecticut Yankee in King Arthur's Court (Mark Twain Library), 2.3333333333333335, 0.5, 0.0014903129657228018}]|\n",
            "|A201GXWKSPNE4C|[{1, 0451515242, Emma (Signet classics), 4.428571428571429, 0.6666666666666666, 0.0014903129657228018}]                            |\n",
            "|A319KYEIAZ3SON|[{1, 0760700435, Sense and sensibility, 5.0, 0.5, 0.0014903129657228018}]                                                          |\n",
            "|A39IY0JU5JI69G|[{1, 0451515242, Emma (Signet classics), 4.428571428571429, 0.6666666666666666, 0.0014903129657228018}]                            |\n",
            "|A3DICRPEYWH9K5|[{1, 1581730470, Emma, 4.428571428571429, 0.5, 0.0014903129657228018}]                                                             |\n",
            "|A3MVAN55WKCGR7|[{1, 0451518845, Jane Eyre (Signet classics), 4.5, 0.6666666666666666, 0.0014903129657228018}]                                     |\n",
            "|A3QZCA4LTTVGAD|[{1, 0613175719, Ulysses, 4.166666666666667, 0.6666666666666666, 0.0014903129657228018}]                                           |\n",
            "|ADFEVWV4EF2IF |[{1, B000JJVHZE, To Kill A Mockingbird, 4.777777777777778, 0.5, 0.0014903129657228018}]                                            |\n",
            "|AHD101501WCN1 |[{1, 0520050894, A Connecticut Yankee in King Arthur's Court (Mark Twain Library), 2.3333333333333335, 0.5, 0.0014903129657228018}]|\n",
            "+--------------+-----------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Rank recommendations by average rating (descending)\n",
        "windowSpec = Window.partitionBy(\"user_id\").orderBy(F.desc(\"avg_rating\"))\n",
        "\n",
        "user_recommendations_sorted = (\n",
        "    user_suggestions_unique\n",
        "    .withColumn(\"rank\", F.row_number().over(windowSpec))\n",
        "    .groupBy(\"user_id\")\n",
        "    .agg(\n",
        "        F.collect_list(\n",
        "            F.struct(\n",
        "                F.col(\"rank\"),\n",
        "                F.col(\"consequent_asin\"),\n",
        "                F.col(\"consequent_title\"),\n",
        "                F.col(\"avg_rating\"),\n",
        "                F.col(\"confidence\"),\n",
        "                F.col(\"support\")\n",
        "            )\n",
        "        ).alias(\"recommended_books_sorted\")\n",
        "    )\n",
        ")\n",
        "\n",
        "# Display sample output for a few users\n",
        "print(\"Top book recommendations generated per user.\")\n",
        "user_recommendations_sorted.show(10, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To personalize results, recommendations were ranked per user using a window function ordered by average rating. The top-ranked items were then aggregated into user-level lists. This approach ensures that each user receives distinct, high-quality book suggestions based on frequent co-review patterns and book popularity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y57FiB4PT98n"
      },
      "source": [
        "### How many books each user gets recommended?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilfv2XpmT-p0",
        "outputId": "a1e60115-ae57-49f0-ba0e-fd7713cfc155"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------+-------------------+\n",
            "|user_id       |num_recommendations|\n",
            "+--------------+-------------------+\n",
            "|A1D2C0WDCSHUWZ|1                  |\n",
            "|A1NT7ED5TATUAM|1                  |\n",
            "|A201GXWKSPNE4C|1                  |\n",
            "|A319KYEIAZ3SON|1                  |\n",
            "|A39IY0JU5JI69G|1                  |\n",
            "|A3DICRPEYWH9K5|1                  |\n",
            "|A3MVAN55WKCGR7|1                  |\n",
            "|A3QZCA4LTTVGAD|1                  |\n",
            "|ADFEVWV4EF2IF |1                  |\n",
            "|AHD101501WCN1 |1                  |\n",
            "|AOUBCAH5BI4FU |1                  |\n",
            "|ARFCORBCTKX1J |1                  |\n",
            "|AUT5ESMCYGBCE |1                  |\n",
            "+--------------+-------------------+\n",
            "\n",
            "ðŸ“š The maximum number of books suggested to a user is: 1\n"
          ]
        }
      ],
      "source": [
        "# Count how many recommendations each user received\n",
        "user_recommendation_count = (\n",
        "    user_recommendations_sorted\n",
        "    .select(\n",
        "        \"user_id\",\n",
        "        F.size(\"recommended_books_sorted\").alias(\"num_recommendations\")\n",
        "    )\n",
        "    .orderBy(F.desc(\"num_recommendations\"))\n",
        ")\n",
        "\n",
        "print(\"Recommendation count per user:\")\n",
        "user_recommendation_count.show(20, truncate=False)\n",
        "\n",
        "# Find the maximum number of recommended books for any user\n",
        "max_recommendations = (\n",
        "    user_recommendation_count\n",
        "    .agg(F.max(\"num_recommendations\").alias(\"max_recommendations\"))\n",
        "    .collect()[0][\"max_recommendations\"]\n",
        ")\n",
        "\n",
        "print(f\"Maximum number of books recommended to a single user: {max_recommendations}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFoekkVJQZ-j"
      },
      "source": [
        "### Top 10 Most Reviewed Books"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGlSyZpkQf55",
        "outputId": "e0d20ddc-2559-45ea-dcca-4a945ee69e09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ”¥ Top 10 Most Reviewed Books:\n",
            "+----------+----------------------------------------------------------------+-----------+\n",
            "|Id        |Title                                                           |num_reviews|\n",
            "+----------+----------------------------------------------------------------+-----------+\n",
            "|B000PC54NG|The Hobbit                                                      |50         |\n",
            "|B000GQG7D2|The Hobbit                                                      |44         |\n",
            "|B000IEZE3G|Harry Potter and The Sorcerer's Stone                           |43         |\n",
            "|B000GQG5MA|The Hobbit; Or, There and Back Again                            |39         |\n",
            "|B000NWQXBA|The Hobbit                                                      |39         |\n",
            "|B000NWU3I4|The Hobbitt, or there and back again; illustrated by the author.|37         |\n",
            "|B000Q032UY|The Hobbit or There and Back Again                              |37         |\n",
            "|B000NDSX6C|The Hobbit                                                      |36         |\n",
            "|B000ILIJE0|The Hobbit There and Back Again                                 |35         |\n",
            "|B000H9R1Q0|The Hobbit                                                      |34         |\n",
            "+----------+----------------------------------------------------------------+-----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "most_reviewed_books = (\n",
        "    sample_df.groupBy(\"Id\", \"Title\")\n",
        "    .agg(F.count(\"User_id\").alias(\"num_reviews\"))\n",
        "    .orderBy(F.desc(\"num_reviews\"))\n",
        ")\n",
        "\n",
        "print(\"\\nTop 10 Most Reviewed Books:\")\n",
        "most_reviewed_books.show(10, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAuFqphaQkDt"
      },
      "source": [
        "### Top 10 Most Recommended Books (Appearing in rules)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MQG7FMuQqOD",
        "outputId": "28c61ecc-4269-459c-abd7-48e6a0657f5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ† Top 10 Most Recommended Books:\n",
            "+---------------+----------------------------------------------------------------+-----------------+\n",
            "|consequent_asin|consequent_title                                                |times_recommended|\n",
            "+---------------+----------------------------------------------------------------+-----------------+\n",
            "|0451515242     |Emma (Signet classics)                                          |2                |\n",
            "|B0007EJ04G     |Leaves of Grass (The Illustrated Modern Library)                |1                |\n",
            "|1581730470     |Emma                                                            |1                |\n",
            "|0520050894     |A Connecticut Yankee in King Arthur's Court (Mark Twain Library)|1                |\n",
            "|0613175719     |Ulysses                                                         |1                |\n",
            "|B000JJVHZE     |To Kill A Mockingbird                                           |1                |\n",
            "|B00087CHVU     |Leaves of grass                                                 |1                |\n",
            "|B00086Q4RO     |Life on the Mississippi, (A Bantam Pathfinder)                  |1                |\n",
            "|0451518845     |Jane Eyre (Signet classics)                                     |1                |\n",
            "|B000ILIJE0     |The Hobbit There and Back Again                                 |1                |\n",
            "+---------------+----------------------------------------------------------------+-----------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "most_recommended_books = (\n",
        "    rules_with_rating.groupBy(\"consequent_asin\", \"consequent_title\")\n",
        "    .agg(F.count(\"antecedent_asin\").alias(\"times_recommended\"))\n",
        "    .orderBy(F.desc(\"times_recommended\"))\n",
        ")\n",
        "\n",
        "print(\"\\nTop 10 Most Recommended Books:\")\n",
        "most_recommended_books.show(10, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  How Often Each Book Was Recommended (Spark FP-Growth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "most_recommended_books_spark = (\n",
        "    user_suggestions_unique\n",
        "    .groupBy(\"consequent_asin\", \"consequent_title\")\n",
        "    .agg(F.countDistinct(\"user_id\").alias(\"num_users_recommended\"))\n",
        "    .orderBy(F.desc(\"num_users_recommended\"))\n",
        ")\n",
        "\n",
        "print(\"Top 10 most recommended books (Spark FP-Growth):\")\n",
        "most_recommended_books_spark.show(10, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXVEgYK6QvW4"
      },
      "source": [
        "\n",
        "### Summary\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIFmU84xQz-P"
      },
      "source": [
        "In this project, FP-Growth was implemented to perform large-scale association rule mining on the Amazon Books Review dataset. Each userâ€™s reviewed books were treated as a basket, enabling the discovery of frequent co-reviewed patterns. Based on these patterns, user-level book recommendations were generated while carefully avoiding duplicates caused by identical titles with different ASINs (e.g., paperback vs. hardcover). Recommendations were ranked using the average review scores of the suggested books to prioritize quality. Finally, analyses of the most-read and most-recommended books provided additional insights into user preferences and global book popularity trends."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPNQKVRdXzLK"
      },
      "source": [
        "# Prof Suggestions\n",
        "\n",
        "Custom FP-Growth Implementation (from scratch using PySpark)\n",
        "\n",
        "**Goal:** Replicate FP-Growth outcomes (association rules) without using Spark's FPGrowth class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbvI9lVtdu4v"
      },
      "source": [
        "### Libaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "eSuEoMSDdouR"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import Row\n",
        "from pyspark.sql.types import ArrayType, StructType, StructField, StringType"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEFJqzapb6HH"
      },
      "source": [
        "### Spark Session Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "ImBFpjBwb3MP"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.appName(\"Custom_FP_Growth_Implementation\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm6lxAAbd1hp"
      },
      "source": [
        "### Create item frequency table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "561mj09Kb3Gk"
      },
      "outputs": [],
      "source": [
        "item_freq = (\n",
        "baskets_id_df\n",
        ".withColumn(\"item\", F.explode(\"basket\"))\n",
        ".groupBy(\"item\")\n",
        ".count()\n",
        ".withColumnRenamed(\"count\", \"support_count\")\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmOjTRmMb3AP"
      },
      "outputs": [],
      "source": [
        "total_baskets = baskets_id_df.count()\n",
        "min_support = 0.001 # same as used in Spark's FP-Growth\n",
        "min_support_count = int(total_baskets * min_support)\n",
        "\n",
        "frequent_items = item_freq.filter(F.col(\"support_count\") >= 3) \n",
        "# I am not using min_support_count as its too big as per me\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0jNv0Edl_VM",
        "outputId": "963d57d5-c8b4-4fb5-8b07-96f902e70332"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-------------+\n",
            "|      item|support_count|\n",
            "+----------+-------------+\n",
            "|B000Q032UY|            6|\n",
            "|B000HH4MYQ|            6|\n",
            "|1901768945|            7|\n",
            "|B000PGI7QI|            6|\n",
            "|0786135034|            6|\n",
            "|8188280046|            6|\n",
            "|B000JQXNSQ|            6|\n",
            "|1566190932|            7|\n",
            "|B0007C10MS|            9|\n",
            "|0141804459|            6|\n",
            "|B000HLFD4K|            6|\n",
            "|B000GQG7D2|            8|\n",
            "|B000ILIJE0|            9|\n",
            "|B000NDSX6C|            7|\n",
            "|B000JJVHZE|            6|\n",
            "|B000NWU3I4|            6|\n",
            "|B000GQG5MA|            6|\n",
            "|0613175719|            7|\n",
            "+----------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#frequent_items.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsjSjTOllOe2",
        "outputId": "c3a9372c-ea97-46bf-b297-9692e6101dbf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#min_support_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkRJKgBvd-QB"
      },
      "source": [
        "### UDF1\n",
        "Takes one userâ€™s basket (a list of items/books that the user has bought or reviewed) and returns all unique pairs of items that occur together in that basket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpS49YMsb246"
      },
      "outputs": [],
      "source": [
        "def generate_pairs(basket):\n",
        "    \"\"\"\n",
        "    Generate all unique, sorted item pairs from a user's basket.\n",
        "    Example:\n",
        "        ['A', 'B', 'B', 'C'] = [('A','B'), ('A','C'), ('B','C')]\n",
        "    \"\"\"\n",
        "    # Defensive checks\n",
        "    if basket is None:\n",
        "        return []\n",
        "    \n",
        "    # Remove duplicates and sort for consistency\n",
        "    basket = sorted(set(basket))\n",
        "    \n",
        "    # Generate pair combinations\n",
        "    pairs = []\n",
        "    for i in range(len(basket)):\n",
        "        for j in range(i + 1, len(basket)):\n",
        "            pairs.append((basket[i], basket[j]))\n",
        "    \n",
        "    return pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate Item Pairs from Each Basket (Custom Step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7g-LsPG_ekz5"
      },
      "outputs": [],
      "source": [
        "# Define schema for UDF output (array of structs)\n",
        "pair_schema = ArrayType(\n",
        "    StructType([\n",
        "        StructField(\"itemA\", StringType(), True),\n",
        "        StructField(\"itemB\", StringType(), True)\n",
        "    ])\n",
        ")\n",
        "\n",
        "# Register UDF\n",
        "generate_pairs_udf = F.udf(generate_pairs, pair_schema)\n",
        "\n",
        "# Apply UDF to each basket, explode, and extract item pairs\n",
        "basket_pairs = (\n",
        "    baskets_id_df\n",
        "    .withColumn(\"pairs\", generate_pairs_udf(F.col(\"basket\")))\n",
        "    .withColumn(\"pair\", F.explode(\"pairs\"))\n",
        "    .select(\n",
        "        F.col(\"pair.itemA\").alias(\"itemA\"),\n",
        "        F.col(\"pair.itemB\").alias(\"itemB\")\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TTsIGUGmNeH",
        "outputId": "ef705e14-88c0-4ecd-f71a-9da1295272a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+----------+\n",
            "|     itemA|     itemB|\n",
            "+----------+----------+\n",
            "|0883686422|B000KW0GVG|\n",
            "|B0006ITZ4S|B000P4VYRO|\n",
            "|0520062388|B000N4XSFC|\n",
            "|0071426442|0844273112|\n",
            "|0071426442|8432208078|\n",
            "|0844273112|8432208078|\n",
            "|B000MWC3FQ|B000PGI7QI|\n",
            "|0786103523|0786193026|\n",
            "|1586217135|1592281044|\n",
            "|0020186509|B00087QGG2|\n",
            "|0020186509|B000PDDG8A|\n",
            "|B00087QGG2|B000PDDG8A|\n",
            "|1593555563|B00086Q244|\n",
            "|0195132653|B00086Q244|\n",
            "|0195132653|B000HJNEYS|\n",
            "|B00086Q244|B000HJNEYS|\n",
            "|1877733075|1887010017|\n",
            "|1404365656|B000KS5WG4|\n",
            "|0670171913|B0006F2EZS|\n",
            "|0520219112|1400060036|\n",
            "+----------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#basket_pairs.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_IUH7lke_Lj"
      },
      "source": [
        "### Compute support for each pair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "5JT3V_0ob2cK"
      },
      "outputs": [],
      "source": [
        "pair_support = (basket_pairs.groupBy(\"itemA\", \"itemB\").count().withColumnRenamed(\"count\", \"pair_support_count\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After generating item pairs for each user basket, the frequency of each unique pair was computed. The resulting support counts represent the number of baskets in which both items co-occur, forming the foundation for association rule generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "QvOuMemAnwU_"
      },
      "outputs": [],
      "source": [
        "# Filter by same min support\n",
        "frequent_pairs = pair_support.filter(F.col(\"pair_support_count\") >= 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYkmDy2Kk1iU",
        "outputId": "961c334e-ee9e-49f2-deae-bce725d6630c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+----------+------------------+\n",
            "|itemA     |itemB     |pair_support_count|\n",
            "+----------+----------+------------------+\n",
            "|B000ILIJE0|B000NWQXBA|3                 |\n",
            "|B0007EJ04G|B00087CHVU|2                 |\n",
            "|B000GRMG5O|B000MS82OQ|2                 |\n",
            "|0451518845|0582528259|2                 |\n",
            "|B000BO2D6Y|B000O0AH22|2                 |\n",
            "|B000JJVHZE|B000K7WNQW|2                 |\n",
            "|0613175719|B000NQ9QF6|2                 |\n",
            "|0520050894|B00086Q4RO|2                 |\n",
            "|0451515242|0760700435|2                 |\n",
            "|B000GQG7D2|B000Q032UY|2                 |\n",
            "|B000GQG7D2|B000NWU3I4|2                 |\n",
            "|1901768945|B000GDLGSG|2                 |\n",
            "|0451515242|1581730470|2                 |\n",
            "|B000GQG5MA|B000NWU3I4|2                 |\n",
            "|0451518845|B000BO2D6Y|2                 |\n",
            "|0533139759|B000MKYL0S|1                 |\n",
            "|0872864243|1596911972|1                 |\n",
            "|0879307455|0940352168|1                 |\n",
            "|0970648219|B000OTS88I|1                 |\n",
            "|0976251604|B000OTS88I|1                 |\n",
            "+----------+----------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#pair_support.orderBy(F.desc(\"pair_support_count\")).show(20, truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaEei7iXfM3Z"
      },
      "source": [
        "###  Generate Association Rules (A â†’ B) with Support, Confidence, Lift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhGYh-2pfNzA"
      },
      "outputs": [],
      "source": [
        "rules = (\n",
        "    frequent_pairs\n",
        "    # Join singleton supports for both items\n",
        "    .join(\n",
        "        frequent_items\n",
        "        .withColumnRenamed(\"item\", \"itemA_support\")\n",
        "        .withColumnRenamed(\"support_count\", \"support_A\"),\n",
        "        F.col(\"itemA\") == F.col(\"itemA_support\"),\n",
        "        \"left\"\n",
        "    )\n",
        "    .join(\n",
        "        frequent_items\n",
        "        .withColumnRenamed(\"item\", \"itemB_support\")\n",
        "        .withColumnRenamed(\"support_count\", \"support_B\"),\n",
        "        F.col(\"itemB\") == F.col(\"itemB_support\"),\n",
        "        \"left\"\n",
        "    )\n",
        "    # Compute metrics\n",
        "    .withColumn(\"support\", F.col(\"pair_support_count\") / F.lit(total_baskets))\n",
        "    .withColumn(\"confidence\", F.col(\"pair_support_count\") / F.col(\"support_A\"))\n",
        "    .withColumn(\n",
        "        \"lift\",\n",
        "        (F.col(\"pair_support_count\") / F.lit(total_baskets))\n",
        "        / ((F.col(\"support_A\") / F.lit(total_baskets)) * (F.col(\"support_B\") / F.lit(total_baskets)))\n",
        "    )\n",
        "    # Keep clean columns\n",
        "    .select(\"itemA\", \"itemB\", \"support\", \"confidence\", \"lift\")\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xyQXgG7kp-3",
        "outputId": "51168110-15eb-43f1-de9d-a30621fcde66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+----------+--------------------+------------------+------------------+\n",
            "|     itemA|     itemB|             support|        confidence|              lift|\n",
            "+----------+----------+--------------------+------------------+------------------+\n",
            "|B000GQG7D2|B000Q032UY|0.001490312965722...|              0.25|55.916666666666664|\n",
            "|B000GQG7D2|B000NWU3I4|0.001490312965722...|              0.25|55.916666666666664|\n",
            "|B000GQG5MA|B000NWU3I4|0.001490312965722...|0.3333333333333333| 74.55555555555556|\n",
            "+----------+----------+--------------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Association rules generated:\", rules.count())\n",
        "rules.orderBy(F.desc(\"confidence\")).show(10, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Association rules were derived by joining frequent pairs with single-item supports to compute key metrics:\n",
        "- Support measures the relative frequency of co-occurrence.\n",
        "- Confidence measures the conditional probability of observing item B given item A.\n",
        "- Lift quantifies how much more likely items are to appear together than if they were independent.\n",
        "\n",
        "Only rules with confidence â‰¥ 0.5 were retained for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RrRNb_UfcyM"
      },
      "source": [
        "### Filter rules by confidence threshold (like minConfidence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "6RAOGevmfeKR"
      },
      "outputs": [],
      "source": [
        "min_confidence = 0.5 #same\n",
        "rules_filtered = rules.filter(F.col(\"confidence\") >= min_confidence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A confidence threshold of 0.5, consistent with the Spark FP-Growth experiment, was applied to retain only strong associations.\n",
        "\n",
        "This filtering step ensures that the remaining rules represent meaningful co-occurrence patterns rather than random coincidences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbY001HZkV6l",
        "outputId": "85dd8619-9a01-4e59-8a19-aa7ffae25656"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+----------+--------------------+----------+------------------+\n",
            "|     itemA|     itemB|             support|confidence|              lift|\n",
            "+----------+----------+--------------------+----------+------------------+\n",
            "|0451515242|0760700435|0.001490312965722...|       0.5|223.66666666666666|\n",
            "|0451515242|1581730470|0.001490312965722...|       0.5|223.66666666666666|\n",
            "+----------+----------+--------------------+----------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"Rules retained with confidence â‰¥ {min_confidence}: {rules_filtered.count()}\")\n",
        "rules_filtered.orderBy(F.desc(\"confidence\")).show(10, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Mx_FyuLfoW1"
      },
      "source": [
        "### Make the rules readable by adding titles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUkpUqJofp0e"
      },
      "outputs": [],
      "source": [
        "rules_readable_prof = (\n",
        "    rules_filtered\n",
        "    # Join antecedent titles\n",
        "    .join(\n",
        "        title_mapping.alias(\"tm1\"),\n",
        "        F.col(\"itemA\") == F.col(\"tm1.Id\"),\n",
        "        \"left\"\n",
        "    )\n",
        "    .withColumnRenamed(\"Title\", \"antecedent_title\")\n",
        "    # Join consequent titles\n",
        "    .join(\n",
        "        title_mapping.alias(\"tm2\"),\n",
        "        F.col(\"itemB\") == F.col(\"tm2.Id\"),\n",
        "        \"left\"\n",
        "    )\n",
        "    .withColumnRenamed(\"Title\", \"consequent_title\")\n",
        "    # Keep relevant columns\n",
        "    .select(\n",
        "        \"itemA\", \"antecedent_title\",\n",
        "        \"itemB\", \"consequent_title\",\n",
        "        \"support\", \"confidence\", \"lift\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JC7EWmPgSuS"
      },
      "source": [
        "### Custom Ranking and Filtering Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOsxZ855gTzw"
      },
      "outputs": [],
      "source": [
        "rules_final_prof = (\n",
        "    rules_readable_prof\n",
        "    # Remove redundant self-pairs (same title in A and B)\n",
        "    .filter(F.col(\"antecedent_title\") != F.col(\"consequent_title\"))\n",
        "    # Weighted ranking metric: combines confidence & lift\n",
        "    .withColumn(\"custom_score\", 0.6 * F.col(\"confidence\") + 0.4 * F.col(\"lift\"))\n",
        "    .orderBy(F.desc(\"custom_score\"))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"âœ… Final ranked rules:\", rules_final_prof.count())\n",
        "rules_final_prof.select(\n",
        "    \"antecedent_title\", \"consequent_title\", \"confidence\", \"lift\", \"custom_score\"\n",
        ").show(10, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2zNfNCPgiSU"
      },
      "source": [
        "### Generate user recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcu63J7vgk85"
      },
      "outputs": [],
      "source": [
        "# Match each user's basket with antecedents to get consequents as recommendations\n",
        "\n",
        "user_suggestions_prof = (\n",
        "    baskets_id_df.alias(\"b\")\n",
        "    # Join where user's basket contains the antecedent item\n",
        "    .join(\n",
        "        rules_final_prof.alias(\"r\"),\n",
        "        F.expr(\"array_contains(b.basket, r.itemA)\"),\n",
        "        \"inner\"\n",
        "    )\n",
        "    .select(\n",
        "        F.col(\"b.User_id\").alias(\"user_id\"),\n",
        "        F.col(\"r.itemB\").alias(\"recommended_asin\"),\n",
        "        F.col(\"r.consequent_title\").alias(\"recommended_title\"),\n",
        "        F.col(\"r.confidence\"),\n",
        "        F.col(\"r.lift\"),\n",
        "        F.col(\"r.custom_score\")\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "hflDWvMlhAqJ"
      },
      "outputs": [],
      "source": [
        "# Remove duplicates per user\n",
        "user_suggestions_unique_prof = user_suggestions_prof.dropDuplicates([\"user_id\", \"recommended_asin\"])\n",
        "\n",
        "# Rank recommendations per user\n",
        "windowSpec_prof = Window.partitionBy(\"user_id\").orderBy(F.desc(\"custom_score\")) # Earlier i used avg. rating to sort the books to recommond\n",
        "\n",
        "user_recommendations_sorted_prof = (\n",
        "  user_suggestions_unique_prof\n",
        "  .withColumn(\"rank\", F.row_number().over(windowSpec_prof))\n",
        "  .groupBy(\"user_id\")\n",
        "  .agg(\n",
        "      F.collect_list(\n",
        "        F.struct(\n",
        "          F.col(\"rank\"),\n",
        "          F.col(\"recommended_asin\"),\n",
        "          F.col(\"consequent_title\"),\n",
        "          F.col(\"confidence\"),\n",
        "          F.col(\"lift\"),\n",
        "          F.col(\"custom_score\"))).alias(\"recommended_books_sorted\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBO2vHqwjSPP",
        "outputId": "6fd55cb0-a09b-4618-a0ae-cb536f84713b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------+-------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|user_id       |recommended_books_sorted                                                                                                                               |\n",
            "+--------------+-------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|A1D2C0WDCSHUWZ|[{1, 0760700435, Sense and sensibility, 0.5, 223.66666666666666, 89.76666666666667}, {2, 1581730470, Emma, 0.5, 223.66666666666666, 89.76666666666667}]|\n",
            "|A319KYEIAZ3SON|[{1, 0760700435, Sense and sensibility, 0.5, 223.66666666666666, 89.76666666666667}, {2, 1581730470, Emma, 0.5, 223.66666666666666, 89.76666666666667}]|\n",
            "|A3DICRPEYWH9K5|[{1, 0760700435, Sense and sensibility, 0.5, 223.66666666666666, 89.76666666666667}, {2, 1581730470, Emma, 0.5, 223.66666666666666, 89.76666666666667}]|\n",
            "|AUT5ESMCYGBCE |[{1, 0760700435, Sense and sensibility, 0.5, 223.66666666666666, 89.76666666666667}, {2, 1581730470, Emma, 0.5, 223.66666666666666, 89.76666666666667}]|\n",
            "+--------------+-------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "user_recommendations_sorted_prof.show(10, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Top 10 Most Recommended Books"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_recommended_books = (\n",
        "    user_suggestions_prof\n",
        "    .groupBy(\"recommended_asin\", \"recommended_title\")\n",
        "    .agg(F.countDistinct(\"user_id\").alias(\"num_users_recommended\"))\n",
        "    .orderBy(F.desc(\"num_users_recommended\"))\n",
        ")\n",
        "\n",
        "print(\"Top 10 most frequently recommended books:\")\n",
        "top_recommended_books.show(10, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I declare that this material, which I now submit for assessment, is entirely my own work and has not been taken from the work of others, save and to the extent that such work has been cited and acknowledged within the text of my work, and including any code produced using generative AI systems. I understand that plagiarism, collusion, and copying are grave and serious offences in the university and accept the penalties that would be imposed should I engage in plagiarism, collusion or copying. This assignment, or any part of it, has not been previously submitted by me/us or any other person for assessment on this or any other course of study.\n",
        "\n",
        " Precious Prince\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhQncWI_kEze"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
